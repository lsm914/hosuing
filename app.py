\
import os
import io
import math
from datetime import datetime, timedelta, timezone

import requests
import pandas as pd
import streamlit as st
import pydeck as pdk
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from dotenv import load_dotenv
from dateutil.relativedelta import relativedelta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
SERVICE_KEY = os.getenv("ODCLOUD_SERVICE_KEY", "")
KAKAO_KEY = os.getenv("KAKAO_REST_KEY", "")
SEOUL_TZ = timezone(timedelta(hours=9))

ALL_AREA_CODES = [100, 200, 300, 312, 338, 360, 400, 410, 500, 513, 560, 600, 621, 680, 690, 700, 712]

CACHE_DIR = ".cache"
GEOCODE_CACHE = os.path.join(CACHE_DIR, "geocode_cache.parquet")
os.makedirs(CACHE_DIR, exist_ok=True)

def today_ymd() -> str:
    return datetime.now(SEOUL_TZ).strftime("%Y-%m-%d")

def two_weeks_range(end_dt: datetime | None = None):
    if end_dt is None:
        end_dt = datetime.now(SEOUL_TZ)
    start = (end_dt - timedelta(days=13)).strftime("%Y-%m-%d")
    end = end_dt.strftime("%Y-%m-%d")
    return start, end

def to_pyeong(m2: float | int | str) -> float:
    try:
        m2 = float(str(m2).replace(",", ""))
        return m2 * 0.3025
    except Exception:
        return math.nan

def safe_int(x):
    try:
        return int(str(x).replace(",", ""))
    except Exception:
        return 0

def safe_float(x):
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return math.nan

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DETAIL = "https://api.odcloud.kr/api/ApplyhomeInfoDetailSvc/v1/getAPTLttotPblancDetail"
BASE_MODEL  = "https://api.odcloud.kr/api/ApplyhomeInfoDetailSvc/v1/getAPTLttotPblancMdl"
BASE_CMPET  = "https://api.odcloud.kr/api/ApplyhomeInfoCmpetRtSvc/v1/getAPTLttotPblancCmpet"

def odcloud_get(url, params):
    params = {**params, "serviceKey": SERVICE_KEY}
    r = requests.get(url, params=params, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"ODCloud API ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")
    return r.json()

def fetch_detail_by_area(area_code: int, start_date: str, end_date: str) -> pd.DataFrame:
    params = {
        "page": 1,
        "perPage": 5000,
        "cond[SUBSCRPT_AREA_CODE::EQ]": area_code,
        "cond[RCRIT_PBLANC_DE::LTE]": end_date,
        "cond[RCRIT_PBLANC_DE::GTE]": start_date,
    }
    js = odcloud_get(BASE_DETAIL, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

def fetch_models(house_manage_no: str) -> pd.DataFrame:
    params = {"page": 1, "perPage": 500, "cond[HOUSE_MANAGE_NO::EQ]": house_manage_no}
    js = odcloud_get(BASE_MODEL, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","MODEL_NO","SUPLY_AR","HOUSE_TY","LTTOT_TOP_AMOUNT","SUPLY_HSHLDCO","SPSPLY_HSHLDCO"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

def fetch_cmpet(house_manage_no: str) -> pd.DataFrame:
    params = {"page": 1, "perPage": 5000, "cond[HOUSE_MANAGE_NO::EQ]": house_manage_no}
    js = odcloud_get(BASE_CMPET, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","HOUSE_TY","REQ_CNT","CMPET_RATE","RESIDE_SENM","SUBSCRPT_RANK_CODE"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§€ì˜¤ì½”ë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_geocode_cache() -> pd.DataFrame:
    if os.path.exists(GEOCODE_CACHE):
        try:
            return pd.read_parquet(GEOCODE_CACHE)
        except Exception:
            pass
    return pd.DataFrame(columns=["address","lat","lon","provider"])

def save_geocode_cache(df: pd.DataFrame):
    try:
        df.drop_duplicates("address").to_parquet(GEOCODE_CACHE, index=False)
    except Exception:
        pass

def kakao_geocode(addr: str):
    if not KAKAO_KEY:
        return None, None
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_KEY}"}
    r = requests.get(url, headers=headers, params={"query": addr}, timeout=10)
    if r.status_code != 200:
        return None, None
    docs = r.json().get("documents", [])
    if not docs:
        return None, None
    x = float(docs[0]["x"])  # lon
    y = float(docs[0]["y"])  # lat
    return y, x

def geocode_addresses(addresses: list[str]) -> pd.DataFrame:
    cache = load_geocode_cache()
    cached = set(cache["address"]) if not cache.empty else set()

    new_rows = []
    geolocator = Nominatim(user_agent="applyhome_geocoder")
    rate_limited = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    for addr in addresses:
        if addr in cached:
            continue
        lat, lon = (None, None)
        provider = None
        if KAKAO_KEY:
            lat, lon = kakao_geocode(addr)
            provider = "kakao" if lat and lon else None
        if not lat or not lon:
            try:
                loc = rate_limited(addr)
                if loc:
                    lat, lon = loc.latitude, loc.longitude
                    provider = provider or "nominatim"
            except Exception:
                pass
        new_rows.append({"address": addr, "lat": lat, "lon": lon, "provider": provider or ""})

    if new_rows:
        new_df = pd.DataFrame(new_rows)
        out = pd.concat([cache, new_df], ignore_index=True)
        save_geocode_cache(out)
        return out
    return cache

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§‘ê³„ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_cover_df(start_date: str, end_date: str, area_codes: list[int]) -> pd.DataFrame:
    frames = []
    for code in area_codes:
        df = fetch_detail_by_area(code, start_date, end_date)
        if not df.empty:
            frames.append(df)
    if not frames:
        return pd.DataFrame(columns=["HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"])
    cover = pd.concat(frames, ignore_index=True).drop_duplicates("HOUSE_MANAGE_NO")
    return cover

def build_detail_df(cover: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for hmno, name, addr, tot, rcpt, mvn, notice in cover[[
        "HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"
    ]].itertuples(index=False):
        models = fetch_models(hmno)
        cmpet = fetch_cmpet(hmno)
        if models.empty:
            continue
        if cmpet.empty:
            for _, m in models.iterrows():
                rows.append({
                    "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                    "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": m.get("HOUSE_TY"), "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                    "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                    "ì ‘ìˆ˜ê±´ìˆ˜": None, "ê²½ìŸë¥ ": None, "ê±°ì£¼ì§€ì—­": None, "ìˆœìœ„": None,
                    "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                })
        else:
            for _, m in models.iterrows():
                ty = m.get("HOUSE_TY")
                sub = cmpet[cmpet["HOUSE_TY"] == ty]
                if sub.empty:
                    rows.append({
                        "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                        "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": ty, "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                        "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                        "ì ‘ìˆ˜ê±´ìˆ˜": None, "ê²½ìŸë¥ ": None, "ê±°ì£¼ì§€ì—­": None, "ìˆœìœ„": None,
                        "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                    })
                else:
                    for _, c in sub.iterrows():
                        rows.append({
                            "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                            "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": ty, "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                            "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                            "ì ‘ìˆ˜ê±´ìˆ˜": c.get("REQ_CNT"), "ê²½ìŸë¥ ": c.get("CMPET_RATE"),
                            "ê±°ì£¼ì§€ì—­": c.get("RESIDE_SENM"), "ìˆœìœ„": c.get("SUBSCRPT_RANK_CODE"),
                            "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                        })
    return pd.DataFrame(rows)

def build_combine_df(detail: pd.DataFrame) -> pd.DataFrame:
    if detail.empty:
        return pd.DataFrame(columns=["ë‹¨ì§€ëª…","ê³µê¸‰ìœ„ì¹˜","ê³µê¸‰ê¸ˆì•¡","ê³µê¸‰ë©´ì ","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)","ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)","ì£¼íƒí˜•"])
    out_rows = []
    keys = sorted(set(zip(detail["ë‹¨ì§€ëª…"], detail["ì£¼íƒí˜•"])))
    for site, ht in keys:
        sub = detail[(detail["ë‹¨ì§€ëª…"]==site) & (detail["ì£¼íƒí˜•"]==ht)]
        if sub.empty:
            continue
        rank1 = sub[sub["ìˆœìœ„"].astype(str)=="1"]["ì ‘ìˆ˜ê±´ìˆ˜"].apply(safe_int).sum()
        rank12 = sub[sub["ìˆœìœ„"].astype(str).isin(["1","2"])]["ì ‘ìˆ˜ê±´ìˆ˜"].apply(safe_int).sum()
        loc = sub.iloc[0]["ê³µê¸‰ìœ„ì¹˜"]
        amt = sub.iloc[0]["ê³µê¸‰ê¸ˆì•¡"]
        area = sub.iloc[0]["ê³µê¸‰ë©´ì "]
        gen = safe_int(sub.iloc[0]["ì¼ë°˜ê³µê¸‰"]); spc = safe_int(sub.iloc[0]["íŠ¹ë³„ê³µê¸‰"])
        total_supply = gen + spc
        out_rows.append({
            "ë‹¨ì§€ëª…": site, "ê³µê¸‰ìœ„ì¹˜": loc, "ê³µê¸‰ê¸ˆì•¡": amt, "ê³µê¸‰ë©´ì ": area,
            "ê³µê¸‰ì„¸ëŒ€ìˆ˜": total_supply, "ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)": rank1, "ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)": rank12, "ì£¼íƒí˜•": ht
        })
    return pd.DataFrame(out_rows)

def build_by_complex_df(combine: pd.DataFrame, detail: pd.DataFrame, cover: pd.DataFrame) -> pd.DataFrame:
    if combine.empty:
        return pd.DataFrame(columns=[
            "ë²ˆí˜¸","ë‹¨ì§€ëª…","ê³µê¸‰ìœ„ì¹˜","ì£¼íƒí˜•","í‰ê· ê³µê¸‰ê¸ˆì•¡","í‰ë‹¨ê°€","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ì ‘ìˆ˜1ìˆœìœ„","ì ‘ìˆ˜1+2ìˆœìœ„","ê²½ìŸë¥ 1","ê²½ìŸë¥ 1+2","ëª¨ì§‘ê³µê³ ì¼","ì…ì£¼ì˜ˆì •ì›”","ì…ì£¼ë…„ë„"
        ])
    g = []
    for (site, ht), grp in combine.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•"], dropna=False):
        grp = grp.copy()
        grp["ì„¸ëŒ€ìˆ˜"] = grp["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].apply(float)
        grp["ê¸ˆì•¡"]   = grp["ê³µê¸‰ê¸ˆì•¡"].apply(lambda x: float(str(x).replace(",","")) if pd.notna(x) else math.nan)
        grp["ë©´ì m2"] = grp["ê³µê¸‰ë©´ì "].apply(lambda x: float(str(x).replace(",","")) if pd.notna(x) else math.nan)
        grp["ë©´ì í‰"] = grp["ë©´ì m2"].apply(to_pyeong)
        grp["í‰ë‹¨ê°€"] = grp.apply(lambda r: (r["ê¸ˆì•¡"]/r["ë©´ì í‰"]) if (pd.notna(r["ë©´ì í‰"]) and r["ë©´ì í‰"]>0) else math.nan, axis=1)

        w = grp["ì„¸ëŒ€ìˆ˜"].sum() if grp["ì„¸ëŒ€ìˆ˜"].notna().any() else 0
        if w<=0:
            avg_amt = grp["ê¸ˆì•¡"].mean()
            avg_py  = grp["í‰ë‹¨ê°€"].mean()
            sup = grp["ì„¸ëŒ€ìˆ˜"].sum()
            r1 = grp["ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)"].sum()
            r12= grp["ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)"].sum()
        else:
            avg_amt = (grp["ê¸ˆì•¡"]*grp["ì„¸ëŒ€ìˆ˜"]).sum()/w
            avg_py  = (grp["í‰ë‹¨ê°€"]*grp["ì„¸ëŒ€ìˆ˜"]).sum()/w
            sup = w
            r1 = grp["ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)"].sum()
            r12= grp["ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)"].sum()

        notice = None
        sub_d = detail[detail["ë‹¨ì§€ëª…"]==site]
        if not sub_d.empty:
            notice = str(sub_d.iloc[0]["ëª¨ì§‘ê³µê³ ì¼"]) or ""
            if len(str(notice))>=7:
                notice = str(notice)[:7]
        mvn = None
        sub_c = cover[cover["HOUSE_NM"]==site]
        if not sub_c.empty:
            mvn = str(sub_c.iloc[0]["MVN_PREARNGE_YM"] or "")
            if len(mvn)==6:
                mvn = f"{mvn[:4]}-{mvn[4:]}"
        mvn_year = mvn[:4] if isinstance(mvn, str) and len(mvn)>=4 else ""

        g.append({
            "ë‹¨ì§€ëª…": site, "ê³µê¸‰ìœ„ì¹˜": grp.iloc[0]["ê³µê¸‰ìœ„ì¹˜"], "ì£¼íƒí˜•": ht,
            "í‰ê· ê³µê¸‰ê¸ˆì•¡": round(avg_amt) if pd.notna(avg_amt) else None,
            "í‰ë‹¨ê°€": round(avg_py,1) if pd.notna(avg_py) else None,
            "ê³µê¸‰ì„¸ëŒ€ìˆ˜": int(round(sup)) if pd.notna(sup) else None,
            "ì ‘ìˆ˜1ìˆœìœ„": int(round(r1)) if pd.notna(r1) else None,
            "ì ‘ìˆ˜1+2ìˆœìœ„": int(round(r12)) if pd.notna(r12) else None,
            "ê²½ìŸë¥ 1": round((r1/sup),2) if sup else None,
            "ê²½ìŸë¥ 1+2": round((r12/sup),2) if sup else None,
            "ëª¨ì§‘ê³µê³ ì¼": notice,
            "ì…ì£¼ì˜ˆì •ì›”": mvn,
            "ì…ì£¼ë…„ë„": mvn_year,
        })

    out = pd.DataFrame(g).sort_values(["ë‹¨ì§€ëª…","ì£¼íƒí˜•"]).reset_index(drop=True)
    numbers = []
    current = 0
    prev = None
    for site in out["ë‹¨ì§€ëª…"]:
        if site != prev:
            current += 1
            prev = site
        numbers.append(current)
    out.insert(0, "ë²ˆí˜¸", numbers)
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—‘ì…€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_excel(by_complex: pd.DataFrame, cover: pd.DataFrame, detail: pd.DataFrame, combine: pd.DataFrame) -> bytes:
    import xlsxwriter  # ensure engine present
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as xw:
        by_complex.to_excel(xw, index=False, sheet_name="ë‹¨ì§€ë³„ì²­ì•½ê²½ìŸë¥ ")
        cover.to_excel(xw, index=False, sheet_name="aptlist(cover)")
        detail.to_excel(xw, index=False, sheet_name="ë‹¨ì§€ì„¸ë¶€ì •ë³´")
        combine.to_excel(xw, index=False, sheet_name="combine")

        wb = xw.book
        ws = xw.sheets["ë‹¨ì§€ë³„ì²­ì•½ê²½ìŸë¥ "]
        money_fmt = wb.add_format({"num_format": "#,##0"})
        one_dec   = wb.add_format({"num_format": "#,##0.0"})
        two_dec   = wb.add_format({"num_format": "0.00"})

        # E: í‰ê· ê³µê¸‰ê¸ˆì•¡, F: í‰ë‹¨ê°€, J/K: ê²½ìŸë¥ 
        ws.set_column("E:E", 12, money_fmt)
        ws.set_column("F:F", 12, one_dec)
        ws.set_column("J:K", 10, two_dec)
        ws.freeze_panes(1, 1)
    buf.seek(0)
    return buf.getvalue()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GitHub Actions Artifact â†’ ìµœì‹  ì—‘ì…€ ë‹¤ìš´ë¡œë“œ & ì¹´ë“œ ë Œë”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, io, re, zipfile, requests
import pandas as pd
import streamlit as st

GH_TOKEN = os.getenv("GH_TOKEN", st.secrets.get("GH_TOKEN", ""))
GH_OWNER = os.getenv("GH_OWNER", st.secrets.get("GH_OWNER", "lsm914"))
GH_REPO  = os.getenv("GH_REPO",  st.secrets.get("GH_REPO",  "hosuing"))
ARTIFACT_NAME = os.getenv("ARTIFACT_NAME", st.secrets.get("ARTIFACT_NAME", "weekly-excel"))

def gh_headers():
    if not GH_TOKEN:
        raise RuntimeError("GH_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ë„£ì–´ì£¼ì„¸ìš”.")
    return {
        "Authorization": f"Bearer {GH_TOKEN}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
    }

def download_latest_artifact_zip(owner: str, repo: str, artifact_name: str) -> bytes:
    """ë¦¬í¬ì˜ artifacts ì¤‘ ì´ë¦„ì´ artifact_nameì¸ ê²ƒ ì¤‘ ìµœì‹  1ê°œ zip ë°”ì´íŠ¸ ë°˜í™˜"""
    url = f"https://api.github.com/repos/{owner}/{repo}/actions/artifacts?per_page=100"
    r = requests.get(url, headers=gh_headers(), timeout=30)
    r.raise_for_status()
    artifacts = r.json().get("artifacts", [])
    candidates = [a for a in artifacts if a.get("name") == artifact_name and not a.get("expired")]
    if not candidates:
        raise RuntimeError(f"'{artifact_name}' ì´ë¦„ì˜ artifactë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    latest = sorted(candidates, key=lambda a: a.get("created_at",""), reverse=True)[0]
    dl = requests.get(latest["archive_download_url"], headers=gh_headers(), timeout=60)
    dl.raise_for_status()
    return dl.content  # zip bytes

def extract_first_excel_from_zip(zip_bytes: bytes) -> tuple[bytes, str]:
    """zip ì•ˆì—ì„œ .xlsx íŒŒì¼ì„ ì°¾ì•„ ë°”ì´íŠ¸ì™€ íŒŒì¼ëª… ë°˜í™˜"""
    with zipfile.ZipFile(io.BytesIO(zip_bytes)) as z:
        xlsx_names = [n for n in z.namelist() if n.lower().endswith(".xlsx")]
        if not xlsx_names:
            raise RuntimeError("zip ë‚´ë¶€ì— .xlsx íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        name = sorted(xlsx_names)[0]
        return z.read(name), os.path.basename(name)

# --------- detail ì‹œíŠ¸ë¥¼ band(ì£¼íƒí˜• ì• 3ìë¦¬)ë¡œ ì§‘ê³„í•´ ì¹´ë“œ ë°ì´í„° ìƒì„± ----------
def _num(x, default=0):
    if pd.isna(x): return default
    s = str(x).strip()
    m = re.search(r"-?\d+(\.\d+)?", s)
    return float(m.group(0)) if m else default

def _band_from_house_ty(s: str) -> int|None:
    if pd.isna(s): return None
    s = str(s).strip()
    m = re.match(r"(\d{2,3})", s)
    if m: return int(m.group(1))
    p = s.split(".")[0]
    m = re.search(r"(\d{2,3})", p)
    return int(m.group(1)) if m else None

def _to_pyeong(m2):
    try: return float(m2)*0.3025
    except: return None

def build_cards_from_detail_sheet(detail_df: pd.DataFrame, cover_df: pd.DataFrame|None=None):
    df = detail_df.copy()
    need = ["ë‹¨ì§€ëª…","ì£¼íƒí˜•","ê³µê¸‰ê¸ˆì•¡","ê³µê¸‰ë©´ì ","ì¼ë°˜ê³µê¸‰","íŠ¹ë³„ê³µê¸‰","ì ‘ìˆ˜ê±´ìˆ˜","ìˆœìœ„","ëª¨ì§‘ê³µê³ ì¼","ê³µê¸‰ìœ„ì¹˜"]
    for c in need:
        if c not in df.columns: df[c] = None

    df["ê³µê¸‰ê¸ˆì•¡"] = df["ê³µê¸‰ê¸ˆì•¡"].apply(_num)
    df["ê³µê¸‰ë©´ì "] = df["ê³µê¸‰ë©´ì "].apply(_num)
    df["ì¼ë°˜ê³µê¸‰"] = df["ì¼ë°˜ê³µê¸‰"].apply(_num)
    df["íŠ¹ë³„ê³µê¸‰"] = df["íŠ¹ë³„ê³µê¸‰"].apply(_num)
    df["ì ‘ìˆ˜ê±´ìˆ˜"] = df["ì ‘ìˆ˜ê±´ìˆ˜"].apply(_num)
    df["ìˆœìœ„"] = df["ìˆœìœ„"].astype(str).str.strip()
    df["band"] = df["ì£¼íƒí˜•"].apply(_band_from_house_ty)
    df["ë©´ì (í‰)"] = df["ê³µê¸‰ë©´ì "].apply(_to_pyeong)
    df["í‰ë‹¨ê°€"] = df.apply(lambda r: (r["ê³µê¸‰ê¸ˆì•¡"]/r["ë©´ì (í‰)"]) if (r["ë©´ì (í‰)"] and r["ë©´ì (í‰)"]>0) else None, axis=1)

    # (ë‹¨ì§€ëª…, ì£¼íƒí˜•) ëŒ€í‘œì¹˜(ì„¸ëŒ€ìˆ˜=ì¼ë°˜+íŠ¹ë³„, ê¸ˆì•¡/í‰ë‹¨ê°€ ë“±)
    by_type = (df.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], dropna=False)
                 .agg(ì¼ë°˜=("ì¼ë°˜ê³µê¸‰","max"), íŠ¹ë³„=("íŠ¹ë³„ê³µê¸‰","max"),
                      ê¸ˆì•¡=("ê³µê¸‰ê¸ˆì•¡","max"), í‰ë‹¨=("í‰ë‹¨ê°€","max"))
                 .reset_index())
    by_type["ì„¸ëŒ€ìˆ˜"] = by_type["ì¼ë°˜"].fillna(0) + by_type["íŠ¹ë³„"].fillna(0)

    def _wavg(x, w):
        x = pd.Series(x).astype(float); w = pd.Series(w).fillna(0).astype(float)
        s, tw = (x*w).sum(), w.sum()
        return (s/tw) if tw>0 else None

    band = (by_type.groupby(["ë‹¨ì§€ëª…","band"], dropna=False)
                  .apply(lambda g: pd.Series({
                      "ê³µê¸‰ì„¸ëŒ€ìˆ˜": g["ì„¸ëŒ€ìˆ˜"].sum(),
                      "ê³µê¸‰ê°€ì•¡": _wavg(g["ê¸ˆì•¡"], g["ì„¸ëŒ€ìˆ˜"]),
                      "í‰ë‹¨ê°€": _wavg(g["í‰ë‹¨"], g["ì„¸ëŒ€ìˆ˜"]),
                  })).reset_index())

    r1  = df[df["ìˆœìœ„"]=="1"].groupby(["ë‹¨ì§€ëª…","band"])["ì ‘ìˆ˜ê±´ìˆ˜"].sum().reset_index(name="ì ‘ìˆ˜1")
    r12 = df[df["ìˆœìœ„"].isin(["1","2"])].groupby(["ë‹¨ì§€ëª…","band"])["ì ‘ìˆ˜ê±´ìˆ˜"].sum().reset_index(name="ì ‘ìˆ˜12")
    band = band.merge(r1, on=["ë‹¨ì§€ëª…","band"], how="left").merge(r12, on=["ë‹¨ì§€ëª…","band"], how="left")
    band[["ì ‘ìˆ˜1","ì ‘ìˆ˜12"]] = band[["ì ‘ìˆ˜1","ì ‘ìˆ˜12"]].fillna(0)
    band["ê²½ìŸë¥ (1ìˆœìœ„)"]   = band.apply(lambda r: round(r["ì ‘ìˆ˜1"]/r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"],2) if r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"] else None, axis=1)
    band["ê²½ìŸë¥ (1,2ìˆœìœ„)"] = band.apply(lambda r: round(r["ì ‘ìˆ˜12"]/r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"],2) if r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"] else None, axis=1)

    meta = (df.groupby("ë‹¨ì§€ëª…").agg(ëª¨ì§‘ê³µê³ ì¼=("ëª¨ì§‘ê³µê³ ì¼","first")).reset_index())
    meta["ëª¨ì§‘ê³µê³ ì›”"] = meta["ëª¨ì§‘ê³µê³ ì¼"].astype(str).str.slice(0,7)
    if cover_df is not None and "HOUSE_NM" in cover_df.columns:
        cov = cover_df.copy()
        cov["ì…ì£¼ì˜ˆì •ì›”"] = cov.get("MVN_PREARNGE_YM","").apply(lambda v: f"{str(v)[:4]}-{str(v)[4:]}" if (pd.notna(v) and len(str(v))==6) else "")
        cov = cov.rename(columns={"HOUSE_NM":"ë‹¨ì§€ëª…"})
        meta = meta.merge(cov[["ë‹¨ì§€ëª…","ì…ì£¼ì˜ˆì •ì›”"]].drop_duplicates("ë‹¨ì§€ëª…"), on="ë‹¨ì§€ëª…", how="left")
    else:
        meta["ì…ì£¼ì˜ˆì •ì›”"] = ""

    out = {}
    for site, g in band.groupby("ë‹¨ì§€ëª…"):
        g = g.sort_values("band")
        rows = g.rename(columns={"band":"íƒ€ì…"})[["íƒ€ì…","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ê³µê¸‰ê°€ì•¡","í‰ë‹¨ê°€","ê²½ìŸë¥ (1ìˆœìœ„)","ê²½ìŸë¥ (1,2ìˆœìœ„)"]].copy()
        # ì†Œê³„(ê°€ì¤‘)
        ts = g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].sum()
        def _fmtn(v): return f"{int(round(v)):,}" if pd.notna(v) else ""
        rows["ê³µê¸‰ì„¸ëŒ€ìˆ˜"] = rows["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].map(_fmtn)
        rows["ê³µê¸‰ê°€ì•¡"]   = rows["ê³µê¸‰ê°€ì•¡"].map(_fmtn)
        rows["í‰ë‹¨ê°€"]     = rows["í‰ë‹¨ê°€"].map(lambda v: f"@{int(round(v)):,}" if pd.notna(v) else "")
        out[site] = {
            "meta": meta[meta["ë‹¨ì§€ëª…"]==site].iloc[0].to_dict() if site in set(meta["ë‹¨ì§€ëª…"]) else {"ëª¨ì§‘ê³µê³ ì›”":"","ì…ì£¼ì˜ˆì •ì›”":""},
            "rows": rows,
            "totals": {
                "ì„¸ëŒ€ìˆ˜": int(ts) if pd.notna(ts) else 0,
                "ê³µê¸‰ê°€ì•¡": int(round((g["ê³µê¸‰ê°€ì•¡"]*g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"]).sum()/ts)) if ts>0 else None,
                "í‰ë‹¨ê°€": int(round((g["í‰ë‹¨ê°€"]*g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"]).sum()/ts)) if ts>0 else None,
                "ê²½ìŸë¥ 1": round(g["ì ‘ìˆ˜1"].sum()/ts,2) if ts>0 else None,
                "ê²½ìŸë¥ 12": round(g["ì ‘ìˆ˜12"].sum()/ts,2) if ts>0 else None,
            }
        }
    return out

def render_card(site: str, info: dict):
    m, rows, t = info["meta"], info["rows"], info["totals"]
    st.markdown(
        f"""
        <div style="border:1px solid #666;padding:8px;margin:10px 0;border-radius:6px;">
          <div style="display:flex;justify-content:space-between;">
            <div style="font-weight:700;">{site}</div>
            <div style="font-size:12px;color:#666;">(ë‹¨ìœ„ : ë§Œì›)</div>
          </div>
          <div style="font-size:12px;margin-top:6px;">
            <b>ëª¨ì§‘ê³µê³ ì¼:</b> {m.get('ëª¨ì§‘ê³µê³ ì›”','')} &nbsp;&nbsp;
            <b>ì…ì£¼ì˜ˆì •ì›”:</b> {m.get('ì…ì£¼ì˜ˆì •ì›”','') or ''}
          </div>
        """, unsafe_allow_html=True
    )
    st.dataframe(rows, use_container_width=True)
    st.markdown(
        f"""
        <div style="display:flex;gap:12px;font-size:13px;margin-top:6px;">
          <div><b>ì†Œê³„</b></div>
          <div>ì„¸ëŒ€ìˆ˜: {t['ì„¸ëŒ€ìˆ˜']:,}</div>
          <div>ê³µê¸‰ê°€ì•¡: {t['ê³µê¸‰ê°€ì•¡']:, if t['ê³µê¸‰ê°€ì•¡'] is not None else ''}</div>
          <div>í‰ë‹¨ê°€: @{t['í‰ë‹¨ê°€']:, if t['í‰ë‹¨ê°€'] is not None else ''}</div>
          <div>ê²½ìŸë¥ (1): {t['ê²½ìŸë¥ 1'] if t['ê²½ìŸë¥ 1'] is not None else ''}</div>
          <div>ê²½ìŸë¥ (1,2): {t['ê²½ìŸë¥ 12'] if t['ê²½ìŸë¥ 12'] is not None else ''}</div>
        </div>
        </div>
        """, unsafe_allow_html=True
    )

st.header("ğŸ“¦ GitHub Actions Artifact ë¶ˆëŸ¬ì˜¤ê¸° â†’ ì¹´ë“œ ë³´ê¸°")
if st.button("ìµœì‹  ì•„í‹°íŒ©íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°"):
    try:
        z = download_latest_artifact_zip(GH_OWNER, GH_REPO, ARTIFACT_NAME)
        xbytes, xname = extract_first_excel_from_zip(z)
        st.success(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {xname}")
        xf = pd.ExcelFile(io.BytesIO(xbytes))
        detail = pd.read_excel(xf, "ë‹¨ì§€ì„¸ë¶€ì •ë³´")
        cover  = pd.read_excel(xf, "aptlist(cover)") if "aptlist(cover)" in xf.sheet_names else None
        cards = build_cards_from_detail_sheet(detail, cover)
        for site in sorted(cards.keys()):
            render_card(site, cards[site])
    except Exception as e:
        st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [NEW] ì—‘ì…€(ë‹¨ì§€ì„¸ë¶€ì •ë³´) â†’ ì¹´ë“œ ìƒì„± íƒ­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import re

def _num(x, default=0):
    """ìˆ«ì íŒŒì‹±: '-', '', '(â–³52)' ê°™ì€ ê°’ ì•ˆì „ ì²˜ë¦¬."""
    if pd.isna(x):
        return default
    s = str(x).strip()
    m = re.search(r"-?\d+(\.\d+)?", s)
    if not m:
        return default
    try:
        return float(m.group(0))
    except:
        return default

def _band_from_house_ty(s: str) -> int:
    """ì£¼íƒí˜• ì•ìª½ 3ìë¦¬(ìˆ«ì)ë¥¼ bandë¡œ. ì˜ˆ: '084.8422A' â†’ 84, '101.9980A' â†’ 101"""
    if pd.isna(s):
        return None
    s = str(s).strip()
    m = re.match(r"(\d{2,3})", s)
    if m:
        return int(m.group(1))
    # ë°±ì—…: ì†Œìˆ˜ì  ì•ìë¦¬
    p = s.split(".")[0]
    m = re.search(r"(\d{2,3})", p)
    return int(m.group(1)) if m else None

def _to_pyeong(m2):
    try:
        return float(m2) * 0.3025
    except:
        return None

def build_cards_from_detail_sheet(detail_df: pd.DataFrame, cover_df: pd.DataFrame|None=None):
    """
    detail_df: 'ë‹¨ì§€ì„¸ë¶€ì •ë³´' ì‹œíŠ¸ DataFrame
    cover_df:  (ì„ íƒ) 'aptlist(cover)' ì‹œíŠ¸ DataFrame (ìˆìœ¼ë©´ ì…ì£¼ì˜ˆì •ì›” í‘œì‹œ)
    return: {ë‹¨ì§€ëª…: {'meta': {...}, 'rows': pd.DataFrame, 'subtotal': dict}}
    """
    df = detail_df.copy()

    # í•„ë“œ ì •ê·œí™”
    need_cols = ["ë‹¨ì§€ëª…","ì£¼íƒí˜•","ê³µê¸‰ê¸ˆì•¡","ê³µê¸‰ë©´ì ","ì¼ë°˜ê³µê¸‰","íŠ¹ë³„ê³µê¸‰",
                 "ì ‘ìˆ˜ê±´ìˆ˜","ìˆœìœ„","ëª¨ì§‘ê³µê³ ì¼","ê³µê¸‰ìœ„ì¹˜","ëª¨ë¸ë²ˆí˜¸"]
    for c in need_cols:
        if c not in df.columns:
            df[c] = None

    df["ê³µê¸‰ê¸ˆì•¡"]  = df["ê³µê¸‰ê¸ˆì•¡"].apply(_num)
    df["ê³µê¸‰ë©´ì "]  = df["ê³µê¸‰ë©´ì "].apply(_num)
    df["ì¼ë°˜ê³µê¸‰"]  = df["ì¼ë°˜ê³µê¸‰"].apply(_num)
    df["íŠ¹ë³„ê³µê¸‰"]  = df["íŠ¹ë³„ê³µê¸‰"].apply(_num)
    df["ì ‘ìˆ˜ê±´ìˆ˜"]  = df["ì ‘ìˆ˜ê±´ìˆ˜"].apply(_num)
    df["ìˆœìœ„"]      = df["ìˆœìœ„"].astype(str).str.strip()
    df["band"]      = df["ì£¼íƒí˜•"].apply(_band_from_house_ty)
    df["ë©´ì (í‰)"]   = df["ê³µê¸‰ë©´ì "].apply(_to_pyeong)
    df["í‰ë‹¨ê°€"]     = df.apply(lambda r: (r["ê³µê¸‰ê¸ˆì•¡"]/r["ë©´ì (í‰)"]) if (r["ë©´ì (í‰)"] and r["ë©´ì (í‰)"]>0) else None, axis=1)

    # (ë‹¨ì§€ëª…, ì£¼íƒí˜•) ë³„ ê³µê¸‰ì„¸ëŒ€ìˆ˜(=ì¼ë°˜+íŠ¹ë³„) ëŒ€í‘œê°’, ê¸ˆì•¡/ë©´ì  ëŒ€í‘œê°’ ì¶”ì¶œ
    # detail ì‹œíŠ¸ëŠ” ì§€ì—­/ìˆœìœ„ë¡œ í–‰ì´ ì¤‘ë³µë˜ë¯€ë¡œ, ê³µê¸‰/ê¸ˆì•¡/ë©´ì ì€ í•œ ë²ˆë§Œ ì¡ì•„ì•¼ ê°€ì¤‘í‰ê· ì´ ì˜¬ë°”ë¦„
    by_type = (
        df.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], dropna=False)
          .agg(ê³µê¸‰ì„¸ëŒ€ìˆ˜=("ì¼ë°˜ê³µê¸‰", "max"))  # ì¼ë‹¨ ì¼ë°˜ê³µê¸‰ë¡œ ë‘ê³  ì•„ë˜ì„œ +íŠ¹ë³„ê³µê¸‰
          .reset_index()
    )
    spc = df.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], dropna=False)["íŠ¹ë³„ê³µê¸‰"].max().reset_index(name="íŠ¹ë³„ê³µê¸‰")
    price = df.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], dropna=False)[["ê³µê¸‰ê¸ˆì•¡","ê³µê¸‰ë©´ì ","ë©´ì (í‰)","í‰ë‹¨ê°€"]].max().reset_index()
    by_type = by_type.merge(spc, on=["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], how="left") \
                     .merge(price, on=["ë‹¨ì§€ëª…","ì£¼íƒí˜•","band"], how="left")
    by_type["ì„¸ëŒ€ìˆ˜"] = (by_type["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].fillna(0) + by_type["íŠ¹ë³„ê³µê¸‰"].fillna(0)).astype(float)

    # (ë‹¨ì§€ëª…, band) ë ˆë²¨ ì§‘ê³„: ê¸ˆì•¡/í‰ë‹¨ê°€ = ì„¸ëŒ€ìˆ˜ ê°€ì¤‘í‰ê· , ì„¸ëŒ€ìˆ˜ = í•©
    def _wavg(series, weights):
        w = pd.Series(weights).fillna(0).astype(float)
        x = pd.Series(series).astype(float)
        s = (x * w).sum()
        tw = w.sum()
        return (s / tw) if tw > 0 else None

    band_level = (
        by_type.groupby(["ë‹¨ì§€ëª…","band"], dropna=False)
               .apply(lambda g: pd.Series({
                   "ê³µê¸‰ì„¸ëŒ€ìˆ˜": g["ì„¸ëŒ€ìˆ˜"].sum(),
                   "ê³µê¸‰ê°€ì•¡": _wavg(g["ê³µê¸‰ê¸ˆì•¡"], g["ì„¸ëŒ€ìˆ˜"]),
                   "í‰ë‹¨ê°€": _wavg(g["í‰ë‹¨ê°€"], g["ì„¸ëŒ€ìˆ˜"]),
               }))
               .reset_index()
    )

    # ê²½ìŸë¥ : ì›ë³¸ dfì—ì„œ ìˆœìœ„ë³„ ì ‘ìˆ˜ í•© â†’ bandë¡œ í•©ì‚°
    rank1 = (df[df["ìˆœìœ„"]=="1"]
             .groupby(["ë‹¨ì§€ëª…","band"])["ì ‘ìˆ˜ê±´ìˆ˜"].sum().reset_index(name="ì ‘ìˆ˜1"))
    rank12 = (df[df["ìˆœìœ„"].isin(["1","2"])]
             .groupby(["ë‹¨ì§€ëª…","band"])["ì ‘ìˆ˜ê±´ìˆ˜"].sum().reset_index(name="ì ‘ìˆ˜12"))
    band_level = band_level.merge(rank1, on=["ë‹¨ì§€ëª…","band"], how="left") \
                           .merge(rank12, on=["ë‹¨ì§€ëª…","band"], how="left")
    band_level["ì ‘ìˆ˜1"]  = band_level["ì ‘ìˆ˜1"].fillna(0)
    band_level["ì ‘ìˆ˜12"] = band_level["ì ‘ìˆ˜12"].fillna(0)
    band_level["ê²½ìŸë¥ (1ìˆœìœ„)"]   = band_level.apply(lambda r: round(r["ì ‘ìˆ˜1"]/r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"], 2) if r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"] else None, axis=1)
    band_level["ê²½ìŸë¥ (1,2ìˆœìœ„)"] = band_level.apply(lambda r: round(r["ì ‘ìˆ˜12"]/r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"], 2) if r["ê³µê¸‰ì„¸ëŒ€ìˆ˜"] else None, axis=1)

    # ë‹¨ì§€ë³„ ë©”íƒ€ (ëª¨ì§‘ê³µê³ ì¼: ì›”ë‹¨ìœ„, ì…ì£¼ì˜ˆì •ì›”ì€ cover ì‹œíŠ¸ ìˆìœ¼ë©´ ì¡°ì¸)
    meta = (df.groupby("ë‹¨ì§€ëª…")
              .agg(ëª¨ì§‘ê³µê³ ì¼=("ëª¨ì§‘ê³µê³ ì¼", "first"), ê³µê¸‰ìœ„ì¹˜=("ê³µê¸‰ìœ„ì¹˜","first"))
              .reset_index())
    def _to_yyyymm(x):
        if pd.isna(x): return ""
        s = str(x)
        return s[:7] if len(s)>=7 else s

    meta["ëª¨ì§‘ê³µê³ ì›”"] = meta["ëª¨ì§‘ê³µê³ ì¼"].map(_to_yyyymm)
    if cover_df is not None and "HOUSE_NM" in cover_df.columns:
        cov = cover_df.copy()
        if "MVN_PREARNGE_YM" in cov.columns:
            cov["ì…ì£¼ì˜ˆì •ì›”"] = cov["MVN_PREARNGE_YM"].map(lambda v: f"{str(v)[:4]}-{str(v)[4:]}" if (pd.notna(v) and len(str(v))==6) else "")
        else:
            cov["ì…ì£¼ì˜ˆì •ì›”"] = ""
        cov = cov.rename(columns={"HOUSE_NM":"ë‹¨ì§€ëª…"})
        meta = meta.merge(cov[["ë‹¨ì§€ëª…","ì…ì£¼ì˜ˆì •ì›”"]].drop_duplicates("ë‹¨ì§€ëª…"), on="ë‹¨ì§€ëª…", how="left")
    else:
        meta["ì…ì£¼ì˜ˆì •ì›”"] = ""

    # ë‹¨ì§€ë³„ ê²°ê³¼ dict
    out = {}
    for site, g in band_level.groupby("ë‹¨ì§€ëª…"):
        g = g.sort_values("band")
        # í‘œì‹œ ì»¬ëŸ¼ êµ¬ì„±
        show = g[["band","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ê³µê¸‰ê°€ì•¡","í‰ë‹¨ê°€","ê²½ìŸë¥ (1ìˆœìœ„)","ê²½ìŸë¥ (1,2ìˆœìœ„)"]].copy()
        show = show.rename(columns={"band":"íƒ€ì…","ê³µê¸‰ê°€ì•¡":"ê³µê¸‰ê°€ì•¡(ë§Œì›)"})
        # ì†Œê³„(ì„¸ëŒ€ìˆ˜ ê°€ì¤‘)
        tot_supply = g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].sum()
        tot_amt    = _wavg(g["ê³µê¸‰ê°€ì•¡"], g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"])
        tot_py     = _wavg(g["í‰ë‹¨ê°€"], g["ê³µê¸‰ì„¸ëŒ€ìˆ˜"])
        tot_r1     = (g["ì ‘ìˆ˜1"].sum()/tot_supply) if tot_supply else None
        tot_r12    = (g["ì ‘ìˆ˜12"].sum()/tot_supply) if tot_supply else None
        subtotal = {
            "íƒ€ì…": "ì†Œê³„",
            "ê³µê¸‰ì„¸ëŒ€ìˆ˜": int(tot_supply) if pd.notna(tot_supply) else None,
            "ê³µê¸‰ê°€ì•¡(ë§Œì›)": round(tot_amt) if pd.notna(tot_amt) else None,
            "í‰ë‹¨ê°€": round(tot_py) if pd.notna(tot_py) else None,
            "ê²½ìŸë¥ (1ìˆœìœ„)": round(tot_r1, 2) if tot_r1 is not None else None,
            "ê²½ìŸë¥ (1,2ìˆœìœ„)": round(tot_r12, 2) if tot_r12 is not None else None,
        }
        # í¬ë§·íŒ…
        def _fmt(df_):
            df_ = df_.copy()
            for c in ["ê³µê¸‰ì„¸ëŒ€ìˆ˜","ê³µê¸‰ê°€ì•¡(ë§Œì›)"]:
                if c in df_.columns: df_[c] = df_[c].map(lambda v: f"{int(round(v)):,}" if pd.notna(v) else "")
            if "í‰ë‹¨ê°€" in df_.columns:
                df_["í‰ë‹¨ê°€"] = df_["í‰ë‹¨ê°€"].map(lambda v: f"@{int(round(v)):,}" if pd.notna(v) else "")
            for c in ["ê²½ìŸë¥ (1ìˆœìœ„)","ê²½ìŸë¥ (1,2ìˆœìœ„)"]:
                if c in df_.columns: df_[c] = df_[c].map(lambda v: f"{v:.2f}" if pd.notna(v) else "")
            return df_

        out[site] = {
            "meta": meta[meta["ë‹¨ì§€ëª…"]==site].iloc[0].to_dict() if site in set(meta["ë‹¨ì§€ëª…"]) else {"ëª¨ì§‘ê³µê³ ì›”":"","ì…ì£¼ì˜ˆì •ì›”":""},
            "rows": _fmt(show),
            "subtotal": subtotal,
        }
    return out

def render_card(site: str, info: dict):
    m = info["meta"]
    rows = info["rows"]
    sub = info["subtotal"]
    st.markdown(
        f"""
        <div style="border:1px solid #666; padding:8px; margin:10px 0; border-radius:6px;">
          <div style="display:flex; justify-content:space-between;">
            <div style="font-weight:700;">{site}</div>
            <div style="font-size:12px; color:#666;">(ë‹¨ìœ„ : ë§Œì›)</div>
          </div>
          <div style="font-size:12px; margin-top:6px;">
            <b>ëª¨ì§‘ê³µê³ ì¼:</b> {m.get('ëª¨ì§‘ê³µê³ ì›”','')} &nbsp;&nbsp;
            <b>ì…ì£¼ì˜ˆì •ì›”:</b> {m.get('ì…ì£¼ì˜ˆì •ì›”','') or ''}
          </div>
        """,
        unsafe_allow_html=True
    )
    st.dataframe(rows, use_container_width=True)
    # ì†Œê³„ ì¤„
    st.markdown(
        f"""
        <div style="display:flex; gap:12px; font-size:13px; margin-top:6px;">
          <div><b>ì†Œê³„</b></div>
          <div>ì„¸ëŒ€ìˆ˜: {sub['ê³µê¸‰ì„¸ëŒ€ìˆ˜']:,} </div>
          <div>ê³µê¸‰ê°€ì•¡: {sub['ê³µê¸‰ê°€ì•¡(ë§Œì›)']:,} </div>
          <div>í‰ë‹¨ê°€: @{sub['í‰ë‹¨ê°€']:,} </div>
          <div>ê²½ìŸë¥ (1): {sub['ê²½ìŸë¥ (1ìˆœìœ„)']:.2f} </div>
          <div>ê²½ìŸë¥ (1,2): {sub['ê²½ìŸë¥ (1,2ìˆœìœ„)']:.2f}</div>
        </div>
        </div>
        """,
        unsafe_allow_html=True
    )

st.header("ğŸ“¥ ì—‘ì…€(ë‹¨ì§€ì„¸ë¶€ì •ë³´) ì—…ë¡œë“œ â†’ ì¹´ë“œ ìƒì„±")
uploaded = st.file_uploader("ìƒì„±ëœ Excel(.xlsx)ì„ ì˜¬ë¦¬ì„¸ìš” (3ë²ˆì§¸ ì‹œíŠ¸: ë‹¨ì§€ì„¸ë¶€ì •ë³´).", type=["xlsx"])
if uploaded:
    x = pd.ExcelFile(uploaded)
    detail = pd.read_excel(x, sheet_name="ë‹¨ì§€ì„¸ë¶€ì •ë³´")
    cover = pd.read_excel(x, sheet_name="aptlist(cover)") if "aptlist(cover)" in x.sheet_names else None
    cards = build_cards_from_detail_sheet(detail, cover)
    # ë‹¨ì§€ëª… ìˆœì„œ ê³ ì •: ë²ˆí˜¸(ìˆë‹¤ë©´) or ì´ë¦„ìˆœ
    for site in sorted(cards.keys()):
        render_card(site, cards[site])

