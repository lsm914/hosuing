\
import os
import io
import math
from datetime import datetime, timedelta, timezone

import requests
import pandas as pd
import streamlit as st
import pydeck as pdk
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from dotenv import load_dotenv
from dateutil.relativedelta import relativedelta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
SERVICE_KEY = os.getenv("ODCLOUD_SERVICE_KEY", "")
KAKAO_KEY = os.getenv("KAKAO_REST_KEY", "")
SEOUL_TZ = timezone(timedelta(hours=9))

ALL_AREA_CODES = [100, 200, 300, 312, 338, 360, 400, 410, 500, 513, 560, 600, 621, 680, 690, 700, 712]

CACHE_DIR = ".cache"
GEOCODE_CACHE = os.path.join(CACHE_DIR, "geocode_cache.parquet")
os.makedirs(CACHE_DIR, exist_ok=True)

def today_ymd() -> str:
    return datetime.now(SEOUL_TZ).strftime("%Y-%m-%d")

def two_weeks_range(end_dt: datetime | None = None):
    if end_dt is None:
        end_dt = datetime.now(SEOUL_TZ)
    start = (end_dt - timedelta(days=13)).strftime("%Y-%m-%d")
    end = end_dt.strftime("%Y-%m-%d")
    return start, end

def to_pyeong(m2: float | int | str) -> float:
    try:
        m2 = float(str(m2).replace(",", ""))
        return m2 * 0.3025
    except Exception:
        return math.nan

def safe_int(x):
    try:
        return int(str(x).replace(",", ""))
    except Exception:
        return 0

def safe_float(x):
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return math.nan

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DETAIL = "https://api.odcloud.kr/api/ApplyhomeInfoDetailSvc/v1/getAPTLttotPblancDetail"
BASE_MODEL  = "https://api.odcloud.kr/api/ApplyhomeInfoDetailSvc/v1/getAPTLttotPblancMdl"
BASE_CMPET  = "https://api.odcloud.kr/api/ApplyhomeInfoCmpetRtSvc/v1/getAPTLttotPblancCmpet"

def odcloud_get(url, params):
    params = {**params, "serviceKey": SERVICE_KEY}
    r = requests.get(url, params=params, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"ODCloud API ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")
    return r.json()

def fetch_detail_by_area(area_code: int, start_date: str, end_date: str) -> pd.DataFrame:
    params = {
        "page": 1,
        "perPage": 5000,
        "cond[SUBSCRPT_AREA_CODE::EQ]": area_code,
        "cond[RCRIT_PBLANC_DE::LTE]": end_date,
        "cond[RCRIT_PBLANC_DE::GTE]": start_date,
    }
    js = odcloud_get(BASE_DETAIL, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

def fetch_models(house_manage_no: str) -> pd.DataFrame:
    params = {"page": 1, "perPage": 500, "cond[HOUSE_MANAGE_NO::EQ]": house_manage_no}
    js = odcloud_get(BASE_MODEL, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","MODEL_NO","SUPLY_AR","HOUSE_TY","LTTOT_TOP_AMOUNT","SUPLY_HSHLDCO","SPSPLY_HSHLDCO"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

def fetch_cmpet(house_manage_no: str) -> pd.DataFrame:
    params = {"page": 1, "perPage": 5000, "cond[HOUSE_MANAGE_NO::EQ]": house_manage_no}
    js = odcloud_get(BASE_CMPET, params)
    rows = js.get("data", [])
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    keep = ["HOUSE_MANAGE_NO","HOUSE_TY","REQ_CNT","CMPET_RATE","RESIDE_SENM","SUBSCRPT_RANK_CODE"]
    for k in keep:
        if k not in df.columns:
            df[k] = None
    return df[keep]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§€ì˜¤ì½”ë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_geocode_cache() -> pd.DataFrame:
    if os.path.exists(GEOCODE_CACHE):
        try:
            return pd.read_parquet(GEOCODE_CACHE)
        except Exception:
            pass
    return pd.DataFrame(columns=["address","lat","lon","provider"])

def save_geocode_cache(df: pd.DataFrame):
    try:
        df.drop_duplicates("address").to_parquet(GEOCODE_CACHE, index=False)
    except Exception:
        pass

def kakao_geocode(addr: str):
    if not KAKAO_KEY:
        return None, None
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_KEY}"}
    r = requests.get(url, headers=headers, params={"query": addr}, timeout=10)
    if r.status_code != 200:
        return None, None
    docs = r.json().get("documents", [])
    if not docs:
        return None, None
    x = float(docs[0]["x"])  # lon
    y = float(docs[0]["y"])  # lat
    return y, x

def geocode_addresses(addresses: list[str]) -> pd.DataFrame:
    cache = load_geocode_cache()
    cached = set(cache["address"]) if not cache.empty else set()

    new_rows = []
    geolocator = Nominatim(user_agent="applyhome_geocoder")
    rate_limited = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    for addr in addresses:
        if addr in cached:
            continue
        lat, lon = (None, None)
        provider = None
        if KAKAO_KEY:
            lat, lon = kakao_geocode(addr)
            provider = "kakao" if lat and lon else None
        if not lat or not lon:
            try:
                loc = rate_limited(addr)
                if loc:
                    lat, lon = loc.latitude, loc.longitude
                    provider = provider or "nominatim"
            except Exception:
                pass
        new_rows.append({"address": addr, "lat": lat, "lon": lon, "provider": provider or ""})

    if new_rows:
        new_df = pd.DataFrame(new_rows)
        out = pd.concat([cache, new_df], ignore_index=True)
        save_geocode_cache(out)
        return out
    return cache

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§‘ê³„ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_cover_df(start_date: str, end_date: str, area_codes: list[int]) -> pd.DataFrame:
    frames = []
    for code in area_codes:
        df = fetch_detail_by_area(code, start_date, end_date)
        if not df.empty:
            frames.append(df)
    if not frames:
        return pd.DataFrame(columns=["HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"])
    cover = pd.concat(frames, ignore_index=True).drop_duplicates("HOUSE_MANAGE_NO")
    return cover

def build_detail_df(cover: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for hmno, name, addr, tot, rcpt, mvn, notice in cover[[
        "HOUSE_MANAGE_NO","HOUSE_NM","HSSPLY_ADRES","TOT_SUPLY_HSHLDCO","RCEPT_BGNDE","MVN_PREARNGE_YM","RCRIT_PBLANC_DE"
    ]].itertuples(index=False):
        models = fetch_models(hmno)
        cmpet = fetch_cmpet(hmno)
        if models.empty:
            continue
        if cmpet.empty:
            for _, m in models.iterrows():
                rows.append({
                    "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                    "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": m.get("HOUSE_TY"), "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                    "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                    "ì ‘ìˆ˜ê±´ìˆ˜": None, "ê²½ìŸë¥ ": None, "ê±°ì£¼ì§€ì—­": None, "ìˆœìœ„": None,
                    "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                })
        else:
            for _, m in models.iterrows():
                ty = m.get("HOUSE_TY")
                sub = cmpet[cmpet["HOUSE_TY"] == ty]
                if sub.empty:
                    rows.append({
                        "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                        "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": ty, "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                        "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                        "ì ‘ìˆ˜ê±´ìˆ˜": None, "ê²½ìŸë¥ ": None, "ê±°ì£¼ì§€ì—­": None, "ìˆœìœ„": None,
                        "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                    })
                else:
                    for _, c in sub.iterrows():
                        rows.append({
                            "ì£¼íƒê´€ë¦¬ë²ˆí˜¸": hmno, "ëª¨ë¸ë²ˆí˜¸": m.get("MODEL_NO"), "ëª¨ì§‘ê³µê³ ì¼": notice,
                            "ê³µê¸‰ë©´ì ": m.get("SUPLY_AR"), "ì£¼íƒí˜•": ty, "ê³µê¸‰ê¸ˆì•¡": m.get("LTTOT_TOP_AMOUNT"),
                            "ì¼ë°˜ê³µê¸‰": m.get("SUPLY_HSHLDCO"), "íŠ¹ë³„ê³µê¸‰": m.get("SPSPLY_HSHLDCO"),
                            "ì ‘ìˆ˜ê±´ìˆ˜": c.get("REQ_CNT"), "ê²½ìŸë¥ ": c.get("CMPET_RATE"),
                            "ê±°ì£¼ì§€ì—­": c.get("RESIDE_SENM"), "ìˆœìœ„": c.get("SUBSCRPT_RANK_CODE"),
                            "ë‹¨ì§€ëª…": name, "ê³µê¸‰ìœ„ì¹˜": addr
                        })
    return pd.DataFrame(rows)

def build_combine_df(detail: pd.DataFrame) -> pd.DataFrame:
    if detail.empty:
        return pd.DataFrame(columns=["ë‹¨ì§€ëª…","ê³µê¸‰ìœ„ì¹˜","ê³µê¸‰ê¸ˆì•¡","ê³µê¸‰ë©´ì ","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)","ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)","ì£¼íƒí˜•"])
    out_rows = []
    keys = sorted(set(zip(detail["ë‹¨ì§€ëª…"], detail["ì£¼íƒí˜•"])))
    for site, ht in keys:
        sub = detail[(detail["ë‹¨ì§€ëª…"]==site) & (detail["ì£¼íƒí˜•"]==ht)]
        if sub.empty:
            continue
        rank1 = sub[sub["ìˆœìœ„"].astype(str)=="1"]["ì ‘ìˆ˜ê±´ìˆ˜"].apply(safe_int).sum()
        rank12 = sub[sub["ìˆœìœ„"].astype(str).isin(["1","2"])]["ì ‘ìˆ˜ê±´ìˆ˜"].apply(safe_int).sum()
        loc = sub.iloc[0]["ê³µê¸‰ìœ„ì¹˜"]
        amt = sub.iloc[0]["ê³µê¸‰ê¸ˆì•¡"]
        area = sub.iloc[0]["ê³µê¸‰ë©´ì "]
        gen = safe_int(sub.iloc[0]["ì¼ë°˜ê³µê¸‰"]); spc = safe_int(sub.iloc[0]["íŠ¹ë³„ê³µê¸‰"])
        total_supply = gen + spc
        out_rows.append({
            "ë‹¨ì§€ëª…": site, "ê³µê¸‰ìœ„ì¹˜": loc, "ê³µê¸‰ê¸ˆì•¡": amt, "ê³µê¸‰ë©´ì ": area,
            "ê³µê¸‰ì„¸ëŒ€ìˆ˜": total_supply, "ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)": rank1, "ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)": rank12, "ì£¼íƒí˜•": ht
        })
    return pd.DataFrame(out_rows)

def build_by_complex_df(combine: pd.DataFrame, detail: pd.DataFrame, cover: pd.DataFrame) -> pd.DataFrame:
    if combine.empty:
        return pd.DataFrame(columns=[
            "ë²ˆí˜¸","ë‹¨ì§€ëª…","ê³µê¸‰ìœ„ì¹˜","ì£¼íƒí˜•","í‰ê· ê³µê¸‰ê¸ˆì•¡","í‰ë‹¨ê°€","ê³µê¸‰ì„¸ëŒ€ìˆ˜","ì ‘ìˆ˜1ìˆœìœ„","ì ‘ìˆ˜1+2ìˆœìœ„","ê²½ìŸë¥ 1","ê²½ìŸë¥ 1+2","ëª¨ì§‘ê³µê³ ì¼","ì…ì£¼ì˜ˆì •ì›”","ì…ì£¼ë…„ë„"
        ])
    g = []
    for (site, ht), grp in combine.groupby(["ë‹¨ì§€ëª…","ì£¼íƒí˜•"], dropna=False):
        grp = grp.copy()
        grp["ì„¸ëŒ€ìˆ˜"] = grp["ê³µê¸‰ì„¸ëŒ€ìˆ˜"].apply(float)
        grp["ê¸ˆì•¡"]   = grp["ê³µê¸‰ê¸ˆì•¡"].apply(lambda x: float(str(x).replace(",","")) if pd.notna(x) else math.nan)
        grp["ë©´ì m2"] = grp["ê³µê¸‰ë©´ì "].apply(lambda x: float(str(x).replace(",","")) if pd.notna(x) else math.nan)
        grp["ë©´ì í‰"] = grp["ë©´ì m2"].apply(to_pyeong)
        grp["í‰ë‹¨ê°€"] = grp.apply(lambda r: (r["ê¸ˆì•¡"]/r["ë©´ì í‰"]) if (pd.notna(r["ë©´ì í‰"]) and r["ë©´ì í‰"]>0) else math.nan, axis=1)

        w = grp["ì„¸ëŒ€ìˆ˜"].sum() if grp["ì„¸ëŒ€ìˆ˜"].notna().any() else 0
        if w<=0:
            avg_amt = grp["ê¸ˆì•¡"].mean()
            avg_py  = grp["í‰ë‹¨ê°€"].mean()
            sup = grp["ì„¸ëŒ€ìˆ˜"].sum()
            r1 = grp["ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)"].sum()
            r12= grp["ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)"].sum()
        else:
            avg_amt = (grp["ê¸ˆì•¡"]*grp["ì„¸ëŒ€ìˆ˜"]).sum()/w
            avg_py  = (grp["í‰ë‹¨ê°€"]*grp["ì„¸ëŒ€ìˆ˜"]).sum()/w
            sup = w
            r1 = grp["ì ‘ìˆ˜ê±´ìˆ˜(1ìˆœìœ„)"].sum()
            r12= grp["ì ‘ìˆ˜ê±´ìˆ˜(1+2ìˆœìœ„)"].sum()

        notice = None
        sub_d = detail[detail["ë‹¨ì§€ëª…"]==site]
        if not sub_d.empty:
            notice = str(sub_d.iloc[0]["ëª¨ì§‘ê³µê³ ì¼"]) or ""
            if len(str(notice))>=7:
                notice = str(notice)[:7]
        mvn = None
        sub_c = cover[cover["HOUSE_NM"]==site]
        if not sub_c.empty:
            mvn = str(sub_c.iloc[0]["MVN_PREARNGE_YM"] or "")
            if len(mvn)==6:
                mvn = f"{mvn[:4]}-{mvn[4:]}"
        mvn_year = mvn[:4] if isinstance(mvn, str) and len(mvn)>=4 else ""

        g.append({
            "ë‹¨ì§€ëª…": site, "ê³µê¸‰ìœ„ì¹˜": grp.iloc[0]["ê³µê¸‰ìœ„ì¹˜"], "ì£¼íƒí˜•": ht,
            "í‰ê· ê³µê¸‰ê¸ˆì•¡": round(avg_amt) if pd.notna(avg_amt) else None,
            "í‰ë‹¨ê°€": round(avg_py,1) if pd.notna(avg_py) else None,
            "ê³µê¸‰ì„¸ëŒ€ìˆ˜": int(round(sup)) if pd.notna(sup) else None,
            "ì ‘ìˆ˜1ìˆœìœ„": int(round(r1)) if pd.notna(r1) else None,
            "ì ‘ìˆ˜1+2ìˆœìœ„": int(round(r12)) if pd.notna(r12) else None,
            "ê²½ìŸë¥ 1": round((r1/sup),2) if sup else None,
            "ê²½ìŸë¥ 1+2": round((r12/sup),2) if sup else None,
            "ëª¨ì§‘ê³µê³ ì¼": notice,
            "ì…ì£¼ì˜ˆì •ì›”": mvn,
            "ì…ì£¼ë…„ë„": mvn_year,
        })

    out = pd.DataFrame(g).sort_values(["ë‹¨ì§€ëª…","ì£¼íƒí˜•"]).reset_index(drop=True)
    numbers = []
    current = 0
    prev = None
    for site in out["ë‹¨ì§€ëª…"]:
        if site != prev:
            current += 1
            prev = site
        numbers.append(current)
    out.insert(0, "ë²ˆí˜¸", numbers)
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—‘ì…€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_excel(by_complex: pd.DataFrame, cover: pd.DataFrame, detail: pd.DataFrame, combine: pd.DataFrame) -> bytes:
    import xlsxwriter  # ensure engine present
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as xw:
        by_complex.to_excel(xw, index=False, sheet_name="ë‹¨ì§€ë³„ì²­ì•½ê²½ìŸë¥ ")
        cover.to_excel(xw, index=False, sheet_name="aptlist(cover)")
        detail.to_excel(xw, index=False, sheet_name="ë‹¨ì§€ì„¸ë¶€ì •ë³´")
        combine.to_excel(xw, index=False, sheet_name="combine")

        wb = xw.book
        ws = xw.sheets["ë‹¨ì§€ë³„ì²­ì•½ê²½ìŸë¥ "]
        money_fmt = wb.add_format({"num_format": "#,##0"})
        one_dec   = wb.add_format({"num_format": "#,##0.0"})
        two_dec   = wb.add_format({"num_format": "0.00"})

        # E: í‰ê· ê³µê¸‰ê¸ˆì•¡, F: í‰ë‹¨ê°€, J/K: ê²½ìŸë¥ 
        ws.set_column("E:E", 12, money_fmt)
        ws.set_column("F:F", 12, one_dec)
        ws.set_column("J:K", 10, two_dec)
        ws.freeze_panes(1, 1)
    buf.seek(0)
    return buf.getvalue()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Applyhome ì£¼ê°„ì§‘ê³„", layout="wide")
st.title("ğŸ¢ ì²­ì•½ì •ë³´(ODCloud) ì£¼ê°„ ìˆ˜ì§‘Â·ì§‘ê³„")

if not SERVICE_KEY:
    st.error("ODCLOUD_SERVICE_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

start_default, end_default = two_weeks_range()
col1, col2, col3 = st.columns(3)
with col1:
    start_date = st.text_input("ì‹œì‘ì¼ (YYYY-MM-DD)", value=start_default)
with col2:
    end_date = st.text_input("ì¢…ë£Œì¼ (YYYY-MM-DD)", value=end_default)
with col3:
    area_mode = st.selectbox("ê²€ìƒ‰ì§€ì—­", ["ì „ì²´","ì§ì ‘ì½”ë“œì…ë ¥"], index=0)

if area_mode == "ì „ì²´":
    area_codes = ALL_AREA_CODES
else:
    codes = st.text_input("ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ì§€ì—­ì½”ë“œë“¤", value="100,200")
    try:
        area_codes = [int(x.strip()) for x in codes.split(",") if x.strip()]
    except Exception:
        st.warning("ì§€ì—­ì½”ë“œ íŒŒì‹± ì˜¤ë¥˜. ê¸°ë³¸ ì „ì²´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        area_codes = ALL_AREA_CODES

run = st.button("ë°ì´í„° ìˆ˜ì§‘/ì§‘ê³„ ì‹¤í–‰")

if run:
    with st.spinner("í‘œì¤€ ëª©ë¡(cover) ìˆ˜ì§‘ ì¤‘â€¦"):
        cover_df = build_cover_df(start_date, end_date, area_codes)
    st.success(f"ë‹¨ì§€ ëª©ë¡ {len(cover_df)}ê±´")
    st.dataframe(cover_df.head(20))

    with st.spinner("ì„¸ë¶€/ê²½ìŸë¥  ì¡°ì¸(detail) êµ¬ì¶• ì¤‘â€¦"):
        detail_df = build_detail_df(cover_df)
    st.success(f"ì„¸ë¶€ í–‰ ìˆ˜ {len(detail_df)}ê±´")

    with st.spinner("(ë‹¨ì§€Ã—ì£¼íƒí˜•) ìš”ì•½(combine) ì‚°ì¶œ ì¤‘â€¦"):
        combine_df = build_combine_df(detail_df)
    st.success(f"ìš”ì•½ í–‰ ìˆ˜ {len(combine_df)}ê±´")

    with st.spinner("ë‹¨ì§€ë³„ ê°€ì¤‘í‰ê· /ê²½ìŸë¥ (by_complex) ì‚°ì¶œ ì¤‘â€¦"):
        by_complex_df = build_by_complex_df(combine_df, detail_df, cover_df)
    st.success(f"ë‹¨ì§€ë³„ í–‰ ìˆ˜ {len(by_complex_df)}ê±´")

    st.subheader("ğŸ“‡ ë‹¨ì§€ ì¹´ë“œ")
    years = ["(ì „ì²´)"] + sorted(list(set(by_complex_df["ì…ì£¼ë…„ë„"].dropna())))
    sel_year = st.selectbox("ì…ì£¼ë…„ë„ í•„í„°", years)
    cards_df = by_complex_df.copy()
    if sel_year != "(ì „ì²´)":
        cards_df = cards_df[cards_df["ì…ì£¼ë…„ë„"]==sel_year]

    for site, grp in cards_df.groupby("ë‹¨ì§€ëª…"):
        st.markdown(f"### {site}")
        grp = grp.sort_values("ì£¼íƒí˜•").head(5)
        st.dataframe(
            grp[["ì£¼íƒí˜•","ê³µê¸‰ì„¸ëŒ€ìˆ˜","í‰ê· ê³µê¸‰ê¸ˆì•¡","í‰ë‹¨ê°€","ê²½ìŸë¥ 1","ê²½ìŸë¥ 1+2"]]
            .rename(columns={"í‰ê· ê³µê¸‰ê¸ˆì•¡":"ê³µê¸‰ê°€ì•¡"})
        )

    st.subheader("ğŸ—ºï¸ ë‹¨ì§€ ìœ„ì¹˜ ì§€ë„")
    addrs = list(set(by_complex_df["ê³µê¸‰ìœ„ì¹˜"].dropna()))
    geo_cache = geocode_addresses(addrs)
    geo_map = geo_cache.set_index("address")[["lat","lon"]].to_dict("index")

    map_df = by_complex_df.copy()
    map_df["lat"] = map_df["ê³µê¸‰ìœ„ì¹˜"].map(lambda a: geo_map.get(a, {}).get("lat"))
    map_df["lon"] = map_df["ê³µê¸‰ìœ„ì¹˜"].map(lambda a: geo_map.get(a, {}).get("lon"))
    map_df = map_df.dropna(subset=["lat","lon"])

    rep = map_df.sort_values(["ë²ˆí˜¸","ì£¼íƒí˜•"]).groupby("ë‹¨ì§€ëª…").first().reset_index()
    rep["label"] = rep["ë²ˆí˜¸"].astype(str)

    if rep.empty:
        st.info("ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ ì—†ì–´ ì§€ë„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£¼ì†Œ í‘œê¸°ë¥¼ ì ê²€í•˜ê±°ë‚˜ KAKAO_REST_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    else:
        midpoint = [rep["lat"].mean(), rep["lon"].mean()]
        layer_text = pdk.Layer(
            "TextLayer",
            data=rep,
            get_position='[lon, lat]',
            get_text='label',
            get_size=16,
            get_color='[0, 0, 0, 255]',
        )
        layer_scatter = pdk.Layer(
            "ScatterplotLayer",
            data=rep,
            get_position='[lon, lat]',
            get_radius=60,
            pickable=True,
        )
        st.pydeck_chart(pdk.Deck(
            map_style=None,
            initial_view_state=pdk.ViewState(latitude=midpoint[0], longitude=midpoint[1], zoom=7),
            layers=[layer_scatter, layer_text],
            tooltip={"text": "{ë‹¨ì§€ëª…}\në²ˆí˜¸ {ë²ˆí˜¸}\n{ê³µê¸‰ìœ„ì¹˜}"}
        ))

    st.subheader("ğŸ“¥ Excel ì‚°ì¶œ")
    xbytes = build_excel(by_complex_df, cover_df, detail_df, combine_df)
    st.download_button(
        label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (ë‹¨ì§€ë³„ì²­ì•½ê²½ìŸë¥  / cover / detail / combine)",
        data=xbytes,
        file_name=f"applyhome_{today_ymd()}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
